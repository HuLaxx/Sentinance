# TorchServe Model Serving Configuration

# Model Archive Commands
# Create model archives (run from apps/ml directory):
#
# LSTM Model:
#   torch-model-archiver \
#     --model-name lstm_price \
#     --version 1.0 \
#     --model-file lstm_model.py \
#     --handler handlers/price_handler.py \
#     --export-path model-store/
#
# GNN Model:
#   torch-model-archiver \
#     --model-name gnn_market \
#     --version 1.0 \
#     --model-file gnn_model.py \
#     --handler handlers/gnn_handler.py \
#     --export-path model-store/

# Start TorchServe:
#   torchserve --start \
#     --ncs \
#     --model-store model-store \
#     --models lstm_price=lstm_price.mar gnn_market=gnn_market.mar

# ===========================================
# CONFIG
# ===========================================

inference_address: "http://0.0.0.0:8085"
management_address: "http://0.0.0.0:8086"
metrics_address: "http://0.0.0.0:8087"

enable_metrics_api: true
metrics_format: prometheus
number_of_netty_threads: 4
job_queue_size: 100

model_store: model-store/

models:
  lstm_price:
    1.0:
      defaultVersion: true
      minWorkers: 1
      maxWorkers: 4
      batchSize: 32
      maxBatchDelay: 100
      responseTimeout: 60
  gnn_market:
    1.0:
      defaultVersion: true
      minWorkers: 1
      maxWorkers: 2
      batchSize: 16
      maxBatchDelay: 200
      responseTimeout: 120

# ===========================================
# RESOURCE LIMITS
# ===========================================

default_workers_per_model: 2
max_request_size: 10485760  # 10MB
max_response_size: 10485760

# GPU Configuration (if available)
# number_of_gpu: 1
# gpu_id: 0
